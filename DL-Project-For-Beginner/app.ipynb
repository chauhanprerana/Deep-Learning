{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "app.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPF-chUT_KVD"
      },
      "source": [
        "#!pip install flask-ngrok"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3Oy2LUXB9Tb",
        "outputId": "ac28dff7-816d-45d5-8f50-a33aa7531553"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F00aGflbo4y2",
        "outputId": "7322ce42-2181-471a-fe7e-7d168c5713e6"
      },
      "source": [
        "from __future__ import division, print_function\r\n",
        "# coding=utf-8\r\n",
        "import sys\r\n",
        "import os\r\n",
        "import glob\r\n",
        "import re\r\n",
        "import numpy as np\r\n",
        "from setuptools import setup\r\n",
        "\r\n",
        "# Keras\r\n",
        "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\r\n",
        "from keras.models import load_model\r\n",
        "from keras.preprocessing import image\r\n",
        "\r\n",
        "# Flask utils\r\n",
        "from flask import Flask, redirect, url_for, request, render_template\r\n",
        "from werkzeug.utils import secure_filename\r\n",
        "#from gevent.pywsgi import WSGIServer\r\n",
        "from flask_ngrok import run_with_ngrok\r\n",
        "from flask import Flask\r\n",
        "\r\n",
        "# Define a flask app\r\n",
        "#app = Flask(__name__)\r\n",
        "app = Flask(__name__, \r\n",
        "            template_folder='/gdrive/My Drive/DL-Project-For-Beginner/templates', \r\n",
        "            static_folder='/gdrive/My Drive/DL-Project-For-Beginner/static')\r\n",
        "\r\n",
        "run_with_ngrok(app)\r\n",
        "\r\n",
        "# Model saved with Keras model.save()\r\n",
        "MODEL_PATH = '/gdrive/My Drive/DL-Project-For-Beginner/vgg19.h5'\r\n",
        "\r\n",
        "# Load your trained model\r\n",
        "model = load_model(MODEL_PATH)\r\n",
        "model.make_predict_function()    ### Necessary\r\n",
        "\r\n",
        "def model_predict(img_path, model):\r\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\r\n",
        "\r\n",
        "    # Preprocessing the image\r\n",
        "    x = image.img_to_array(img)\r\n",
        "    # x = np.true_divide(x, 255)\r\n",
        "    x = np.expand_dims(x, axis=0)\r\n",
        "\r\n",
        "    # Be careful how your trained model deals with the input\r\n",
        "    # otherwise, it won't make correct prediction!\r\n",
        "    x = preprocess_input(x)\r\n",
        "\r\n",
        "    preds = model.predict(x)\r\n",
        "    return preds\r\n",
        "\r\n",
        "\r\n",
        "@app.route('/', methods=['GET'])\r\n",
        "def index():\r\n",
        "    # Main page\r\n",
        "    return render_template('index.html')\r\n",
        "\r\n",
        "\r\n",
        "@app.route('/predict', methods=['GET', 'POST'])\r\n",
        "def upload():\r\n",
        "    if request.method == 'POST':\r\n",
        "        # Get the file from post request\r\n",
        "        f = request.files['file']\r\n",
        "\r\n",
        "        # Save the file to ./uploads\r\n",
        "        #basepath = os.path.dirname(__file__)\r\n",
        "        basepath = '/gdrive/My Drive/DL-Project-For-Beginner/'\r\n",
        "        file_path = os.path.join(basepath, 'uploads', secure_filename(f.filename))\r\n",
        "        f.save(file_path)\r\n",
        "\r\n",
        "        # Make prediction\r\n",
        "        preds = model_predict(file_path, model)\r\n",
        "\r\n",
        "        # Process your result for human\r\n",
        "        # pred_class = preds.argmax(axis=-1)            # Simple argmax\r\n",
        "        pred_class = decode_predictions(preds, top=1)   # ImageNet Decode\r\n",
        "        result = str(pred_class[0][0][1])               # Convert to string\r\n",
        "        return result\r\n",
        "    return None\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "  app.run()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://472fd9be4bd3.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [23/Dec/2020 16:05:09] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [23/Dec/2020 16:05:10] \"\u001b[37mGET /static/js/main.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [23/Dec/2020 16:05:10] \"\u001b[37mGET /static/css/main.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [23/Dec/2020 16:05:12] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [23/Dec/2020 16:05:29] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [23/Dec/2020 16:05:48] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [23/Dec/2020 16:06:01] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [23/Dec/2020 16:06:22] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [23/Dec/2020 16:06:34] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [23/Dec/2020 16:06:46] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [23/Dec/2020 16:07:03] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [23/Dec/2020 16:07:34] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [23/Dec/2020 16:07:46] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [23/Dec/2020 16:08:00] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [23/Dec/2020 16:08:30] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [23/Dec/2020 16:08:43] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [23/Dec/2020 16:09:03] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [23/Dec/2020 16:10:20] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}